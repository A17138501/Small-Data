{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc5b980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[normalize] Local raw not found. Loading from HF: Salesforce/xlam-function-calling-60k:train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 60000/60000 [00:00<00:00, 145472.15 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[normalize] Loaded 60000 raw rows\n",
      "[normalize] Columns: ['id', 'query', 'answers', 'tools']\n",
      "[normalize] Kept 60000 normalized rows\n",
      "[normalize] Wrote data/processed/apigen_normalized.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Normalization: produce a 3-column CSV with:\n",
    "  - query: natural language question\n",
    "  - tools: JSON string (list of tool specs)\n",
    "  - gold_call: JSON string {\"name\": ..., \"arguments\": {...}}\n",
    "\n",
    "Input preference:\n",
    "  1) data/raw/apigen.csv if present\n",
    "  2) else: load from HF datasets API\n",
    "\n",
    "Output:\n",
    "  data/processed/apigen_normalized.csv\n",
    "\"\"\"\n",
    "import os, json, argparse\n",
    "from typing import Any, Dict, Optional\n",
    "import pandas as pd\n",
    "try:\n",
    "    from datasets import load_dataset\n",
    "except Exception:\n",
    "    load_dataset = None\n",
    "\n",
    "RAW_PATH = \"data/raw/apigen.csv\"\n",
    "OUT_PATH = \"data/processed/apigen_normalized.csv\"\n",
    "\n",
    "# 兼容常见变体列名\n",
    "QUERY_KEYS = [\n",
    "    \"query\", \"prompt\", \"question\", \"input\", \"instruction\", \"user_query\", \"inputs\", \"task\"\n",
    "]\n",
    "TOOLS_KEYS = [\n",
    "    \"tools\", \"tool_definitions\", \"tool_defs\", \"tools_json\", \"tool_schema\",\n",
    "    \"function_definitions\", \"available_tools\", \"tool_list\"\n",
    "]\n",
    "ANSWERS_KEYS = [\n",
    "    \"answers\", \"answer\", \"calls\", \"tool_calls\", \"gold_calls\", \"gold_actions\",\n",
    "    \"target\", \"gold\", \"gold_call\"\n",
    "]\n",
    "\n",
    "def _safe_json_load(x):\n",
    "    if isinstance(x, (dict, list)): return x\n",
    "    if pd.isna(x): return None\n",
    "    if isinstance(x, (int, float, bool)): return x\n",
    "    try:\n",
    "        return json.loads(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _extract_query(row: Dict[str, Any]) -> Optional[str]:\n",
    "    for k in QUERY_KEYS:\n",
    "        v = row.get(k)\n",
    "        if isinstance(v, str) and v.strip():\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "def _extract_tools(row: Dict[str, Any]) -> Optional[list]:\n",
    "    # 1) 优先从常见的工具列取\n",
    "    for k in TOOLS_KEYS:\n",
    "        if k in row:\n",
    "            v = row.get(k)\n",
    "            v = v if isinstance(v, (list, dict)) else _safe_json_load(v)\n",
    "            if isinstance(v, list):\n",
    "                return v\n",
    "            if isinstance(v, dict):\n",
    "                # dict 形式：按 name 展开\n",
    "                return [{\"name\": kk, **(vv if isinstance(vv, dict) else {})} for kk, vv in v.items()]\n",
    "    # 2) 兜底：如果这行只有一个 gold 的 tool_name，也至少提供一个最小工具清单\n",
    "    tn = row.get(\"tool_name\") or row.get(\"function_name\") or row.get(\"name\")\n",
    "    if isinstance(tn, str) and tn.strip():\n",
    "        return [{\"name\": tn.strip()}]\n",
    "    return None\n",
    "\n",
    "def _normalize_call_obj(x) -> Optional[dict]:\n",
    "    if not isinstance(x, dict): return None\n",
    "    name = x.get(\"tool_name\") or x.get(\"name\") or x.get(\"function_name\")\n",
    "    args = x.get(\"arguments\") or x.get(\"args\") or x.get(\"parameters\") or {}\n",
    "    if not isinstance(args, dict):\n",
    "        try:\n",
    "            args = json.loads(args)\n",
    "            if not isinstance(args, dict):\n",
    "                args = {\"_raw\": args}\n",
    "        except Exception:\n",
    "            args = {\"_raw\": args}\n",
    "    if name:\n",
    "        return {\"name\": str(name), \"arguments\": args}\n",
    "    return None\n",
    "\n",
    "def _extract_gold_call(row: Dict[str, Any]) -> Optional[dict]:\n",
    "    # 1) 先看 answers/calls 类字段\n",
    "    for k in ANSWERS_KEYS:\n",
    "        if k in row:\n",
    "            val = row.get(k)\n",
    "            val = val if isinstance(val, (list, dict)) else _safe_json_load(val)\n",
    "            if isinstance(val, list) and val:\n",
    "                c = _normalize_call_obj(val[0])\n",
    "                if c: return c\n",
    "            if isinstance(val, dict):\n",
    "                c = _normalize_call_obj(val)\n",
    "                if c: return c\n",
    "    # 2) minpeter/parsed 常见：单行拆分为 tool_name + arguments\n",
    "    tn = row.get(\"tool_name\") or row.get(\"function_name\") or row.get(\"name\")\n",
    "    if tn:\n",
    "        args = row.get(\"arguments\") or row.get(\"args\") or row.get(\"parameters\") or {}\n",
    "        args = args if isinstance(args, dict) else (_safe_json_load(args) or {})\n",
    "        if not isinstance(args, dict):\n",
    "            args = {\"_raw\": args}\n",
    "        return {\"name\": str(tn), \"arguments\": args}\n",
    "    return None\n",
    "\n",
    "def load_source(repo: str, split: str) -> pd.DataFrame:\n",
    "    if os.path.exists(RAW_PATH):\n",
    "        print(f\"[normalize] Reading local raw: {RAW_PATH}\")\n",
    "        return pd.read_csv(RAW_PATH)\n",
    "    if load_dataset is None:\n",
    "        raise RuntimeError(\"datasets.load_dataset not available and no local raw found.\")\n",
    "    print(f\"[normalize] Local raw not found. Loading from HF: {repo}:{split}\")\n",
    "    ds = load_dataset(repo, split=split)\n",
    "    return ds.to_pandas()\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--repo\", default=\"Salesforce/xlam-function-calling-60k\")\n",
    "    parser.add_argument(\"--split\", default=\"train\")\n",
    "    parser.add_argument(\"--out\", default=OUT_PATH)\n",
    "    # 关键：在 notebook 里可能会注入未知参数 (-f=...); 用 parse_known_args 忽略\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    os.makedirs(os.path.dirname(args.out), exist_ok=True)\n",
    "    df = load_source(args.repo, args.split)\n",
    "    print(f\"[normalize] Loaded {len(df)} raw rows\")\n",
    "    print(f\"[normalize] Columns: {list(df.columns)[:20]}{' ...' if len(df.columns)>20 else ''}\")\n",
    "\n",
    "    norm_rows = []\n",
    "    for _, row_s in df.iterrows():\n",
    "        row = row_s.to_dict()\n",
    "        q = _extract_query(row)\n",
    "        t = _extract_tools(row)\n",
    "        g = _extract_gold_call(row)\n",
    "        if q is None or t is None or g is None:\n",
    "            continue\n",
    "        norm_rows.append({\n",
    "            \"query\": q,\n",
    "            \"tools\": json.dumps(t, ensure_ascii=False),\n",
    "            \"gold_call\": json.dumps(g, ensure_ascii=False),\n",
    "        })\n",
    "\n",
    "    out_df = pd.DataFrame(norm_rows, columns=[\"query\", \"tools\", \"gold_call\"])\n",
    "    print(f\"[normalize] Kept {len(out_df)} normalized rows\")\n",
    "    out_df.to_csv(args.out, index=False, encoding=\"utf-8\")\n",
    "    print(f\"[normalize] Wrote {args.out}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
